

1. Frontend
    1. Space key: hold color of superpixels during annotation : DONE
    2. Enter key: hold predicted labels: DONE
    3. OR relation between ticks and button press : DONE
    4. Users annotation should not be impacted once we get response from backend: DONE
        --> users can continue annotation while model is training: DONE
        --> Move loading button to top or side: DONE
        --> latest labels will be used for retraining: DONE
        --> update the old superpixels --> just show the latest ones: DONE
    5. Different modes for annotation
        1. Only annotate recommended: DONE
        2. Correct mistake prediction during annotation : DONE
           --> this can be used as feedback to model in addition to recommended regions: DONE
    
    6. Mask out forests should not be shown during recommemdation
        --> for some superpixels, majority might be forest and only a few flood/dry ???
            --> if we only show flood/dry it can be difficult to see on Frontend ???
        --> ban them from being annotated: TODO
        --> don't include them in loss computation: include propagated labels in loss computation

2. Start from a pretrained model (model trained on 2 or 3 regions): DONE

3. Loss function: DONE
    1. Compute difference with the mean of all (don't take any arbitrary transformation): DONE
    

4. Acquisition function: how do they go from pixel to patch; do they take avg, min, max??? --> average (torch.mean())
    --> start with full image and get its entropy
    --> divide into rectangular regions
    --> get average entropy of divided rectangular regions
    --> select ones with highest entropy

        1. our case we can try min first and then avg
            --> min gives most uncertain
        2. try entropy from EqAL paper: DONE

5. Superpixels



01/10

1. Remove functionalities related to topology based segmentation: DONE
2. Remove logging feature: DONE
3. Use propagated labels for retraining: DONE
4. Save triangulation on disk and load from there: DONE
     --> check whether it is network issue for slow down --> internet issue
5. Colormap for superpixel: Red -> White (2 extreme colors): DONE
6. Highlights holes in superpixels (obvious colors like light blue): DONE
   --> if superpixel is recommended but majority are forests, highlight non-forest with blue color: DONE
7. Display metrics in each iteration when we get the prediction: DONE

8. ban forests from being annotated 
    --> show cross mark: PARTIALLY DONE
    --> add sound: TODO

9. 8 versions of self-consistency in acquisition: coding DONE
 --> use ticks on frontend to decide the configuration: DONE 
 --> configure URL as well: TODO
 --> find combination of best later: TODO

10. Forest Model: TODO (Switch to Slides)
    --> Our model gives initial prediction
    --> User can correct the prediction on frontend
            if confirmed (painted green): 
                FOREST 
            else if erased (painted blue): 
                NOT FOREST
            else:
                UNKNOWN
    --> Retrain the forest model ???
        --> Our initial model uses confidence score based on user's annotation
        --> When we get user feedback from frontend we can do similar:
            --> FOREST pixels: set confidence score to 0
            --> NOT FOREST pixels: set confidence score to 1
            --> UNKNOWN pixels: set confidence score to 0.5


11. Read paper sent by Dr. Wang: DONE
12. Split superpixels if partially annotated: at the END
13. penalize corrected annotation from users if model still predicts the old labels: at the END
12. Superpixels improvement: at the END 


01/17
1. Change self-consistency to Uncertainty Measure: DONE
2. Transform-level Agg, Pixel-level Agg: Frontend: DONE
3. Forest Model: Switch to slides for details
4. Read paper and be ready for discussion next week: DONE
5. change notations on slides: TODO


01/24
Forest model
1. prepare detailed instructions for Forest Model: DONE
2. Change retrain button and Download button's UI: DONE


Active Learning

1. Figure out how to use TOD as well as Uncertainty-Measure: DONE
2. Study TOD code; Acquisition and Loss function using EMA: DONE
3. For unsupervised loss, only take unlabeled regions: DONE
4. Metrics: remove quotation, Acc on top (only one), space between dry and flood metrics, space after accuracy, Align: DONE
5. When Entropy is selected, Minimum option should be disabled; For probability, Max option should be disabled: DONE


About TOD Code:
1. main_TOD.py: train_epoch() function, why do we need res_loss? Its always zero, right? 
   scores and cons_scores used to compute mse_loss looks exactly same to me!

01/31
1. Integrate forest score in acquisition function instead of banning them: try log prob for + and - for voting down superpixel: AND relation

2. make instructions more formal; even add enter password instructions --> add toy example: DONE
3. also Download annotation (blue and green): DONE
4. create a sign up form in frontend for students --> UAB's Office 365 Form: DONE
 --> 2 images per students
 --> make it work for toy example
 --> attach toy example to add restrictions
 --> screenshots


 02/14
1. A(orig [offset/entropy]) + B(variance by transformation) + C(COD): DONE
2. Use almost annotated data to simulate the experiment and get the best values for lambdas: In progress
3. Do this for loss function beta-1 and beta-2 as well: TODO
4. Try features before sigmoid as well for COD: TODO