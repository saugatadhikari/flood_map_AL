

1. Frontend
    1. Space key: hold color of superpixels during annotation : DONE
    2. Enter key: hold predicted labels: DONE
    3. OR relation between ticks and button press : DONE
    4. Users annotation should not be impacted once we get response from backend: DONE
        --> users can continue annotation while model is training: DONE
        --> Move loading button to top or side: DONE
        --> latest labels will be used for retraining: DONE
        --> update the old superpixels --> just show the latest ones: DONE
    5. Different modes for annotation
        1. Only annotate recommended: DONE
        2. Correct mistake prediction during annotation : DONE
           --> this can be used as feedback to model in addition to recommended regions: DONE
    
    6. Mask out forests should not be shown during recommemdation
        --> for some superpixels, majority might be forest and only a few flood/dry ???
            --> if we only show flood/dry it can be difficult to see on Frontend ???
        --> ban them from being annotated: TODO
        --> don't include them in loss computation: include propagated labels in loss computation

2. Start from a pretrained model (model trained on 2 or 3 regions): DONE

3. Loss function: DONE
    1. Compute difference with the mean of all (don't take any arbitrary transformation): DONE
    

4. Acquisition function: how do they go from pixel to patch; do they take avg, min, max??? --> average (torch.mean())
    --> start with full image and get its entropy
    --> divide into rectangular regions
    --> get average entropy of divided rectangular regions
    --> select ones with highest entropy

        1. our case we can try min first and then avg
            --> min gives most uncertain
        2. try entropy from EqAL paper: DONE

5. Superpixels



TODO:
1. Remove functionalities related to topology based segmentation: DONE
2. Remove logging feature: DONE
3. Use propagated labels for retraining: DONE
4. Save traingulation on disk and load from there: DONE
    TODO: check whether it is network issue for slow down???
5. Colormap for superpixel: Red -> White (2 extreme colors): DONE
6. Highlights holes in superpixels (obvious colors like light blue): DONE
   --> if superpixel is recommemded but majority are forests, highlight non-forest with blue color: DONE
7. Display metrics in each iteration when we get the prediction: DONE

8. ban forests from being annotated 
    --> show cross mark: PARTIALLY DONE

9. 8 versions of self-consistency in acquisition: coding DONE
 --> use ticks on frontend to decide the configuration: DONE 
 --> configure URL as well: TODO
 --> find combination of best later: TODO

10. Forest Model: TODO (Switch to Slides)
    --> Our model gives initial prediction
    --> User can correct the prediction on frontend
            if confirmed (painted green): 
                FOREST 
            else if erased (painted blue): 
                NOT FOREST
            else:
                UNKNOWN
    --> Retrain the forest model ???
        --> Our initial model uses confidence score based on user's annotation
        --> When we get user feedback from frontend we can do similar:
            --> FOREST pixels: set confidence score to 0
            --> NOT FOREST pixels: set confidence score to 1
            --> UNKNOWN pixels: set confidence score to 0.5

11. Read paper by Dr. Wang: TODO
 
12. Split superpixels if partially annotated
13. penalize corrected annotation from users if model still predicts the old labels: at the END